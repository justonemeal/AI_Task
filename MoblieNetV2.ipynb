{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ac-iWwlyew4o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact\n",
        "\n",
        "random_seed = 2022\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_files(data_dir, sub_dir):\n",
        "    image_format = [\"jpeg\", \"jpg\", \"png\"]\n",
        "\n",
        "    image_files = []\n",
        "    images_dir = os.path.join(data_dir, sub_dir)\n",
        "    for file_path in os.listdir(images_dir):\n",
        "        if file_path.split(\".\")[-1] in image_format:\n",
        "            image_files.append(os.path.join(sub_dir, file_path))\n",
        "    return image_files"
      ],
      "metadata": {
        "id": "br_KJxhvez32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_RGB_image(data_dir, file_name):\n",
        "    image_file = os.path.join(data_dir, file_name)\n",
        "    image = cv2.imread(image_file)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    return image"
      ],
      "metadata": {
        "id": "FR0nr4S9e6lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
        "class_list = [\"Bacterial\", \"fungal\", \"healthy\"]\n",
        "\n",
        "class Chest_dataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        Bacterial_list = list_image_files(data_dir, \"Bacterial\")\n",
        "        fungal_list = list_image_files(data_dir, \"fungal\")\n",
        "        healthy_list = list_image_files(data_dir, \"healthy\")\n",
        "\n",
        "\n",
        "        self.files_path = Bacterial_list, fungal_list, healthy_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        target = class_list.index(self.files_path[index].split(os.sep)[0])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            target = torch.Tensor([target]).long()\n",
        "\n",
        "        return {\"image\":image, \"target\":target}\n",
        "\n",
        "dset = Chest_dataset(train_data_dir)"
      ],
      "metadata": {
        "id": "brmbvRZbe8_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
        "class_list = [\"Bacterial\", \"fungal\", \"healthy\"]\n",
        "\n",
        "class Chest_dataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "        self.Bacterial_list = list_image_files(data_dir, \"Bacterial\")\n",
        "        self.fungal_list = list_image_files(data_dir, \"fungal\")\n",
        "        self.healthy_list = list_image_files(data_dir, \"healthy\")\n",
        "\n",
        "        self.files_path = self.Bacterial_list + self.fungal_list + self.healthy_list\n",
        "\n",
        "        self.targets = ([0] * len(self.Bacterial_list) +\n",
        "                        [1] * len(self.fungal_list) +\n",
        "                        [2] * len(self.healthy_list))\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get image file path and target\n",
        "        image_file = os.path.join(self.data_dir, self.files_path[index])\n",
        "        image = cv2.imread(image_file)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        target = torch.tensor(target).long()\n",
        "\n",
        "        return {\"image\": image, \"target\": target}\n"
      ],
      "metadata": {
        "id": "x67j9Mvxhm9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                         std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "train_dset = Chest_dataset(train_data_dir, transformer)\n",
        "index = 200\n",
        "image = train_dset[index][\"image\"]\n",
        "label = train_dset[index][\"target\"]\n",
        "\n",
        "print(image.shape, label)"
      ],
      "metadata": {
        "id": "Xn8HcZ0re_mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloader(train_data_dir, val_data_dir):\n",
        "    dataloaders = {}\n",
        "    train_dset = Chest_dataset(train_data_dir, transformer)\n",
        "    dataloaders[\"train\"] = DataLoader(train_dset, batch_size=4, shuffle=True, drop_last=True)\n",
        "    val_dset = Chest_dataset(val_data_dir, transformer)\n",
        "    dataloaders[\"val\"] = DataLoader(val_dset, batch_size=1, shuffle=False, drop_last=False)\n",
        "    return dataloaders"
      ],
      "metadata": {
        "id": "BV_N8-34fGc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/drive/MyDrive/lettuce/train/\"\n",
        "val_data_dir = \"/content/drive/MyDrive/lettuce/test/\"\n",
        "dataloaders = build_dataloader(train_data_dir, val_data_dir)"
      ],
      "metadata": {
        "id": "vEsXcdhOfH3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, t, stride = 1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "\n",
        "        expand = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels * t, 1, bias = False),\n",
        "            nn.BatchNorm2d(in_channels * t),\n",
        "            nn.ReLU6(inplace = True),\n",
        "        )\n",
        "        depthwise = nn.Sequential(\n",
        "            nn.Conv2d(in_channels * t, in_channels * t, 3, stride = stride, padding = 1, groups = in_channels * t, bias = False),\n",
        "            nn.BatchNorm2d(in_channels * t),\n",
        "            nn.ReLU6(inplace = True),\n",
        "        )\n",
        "        pointwise = nn.Sequential(\n",
        "            nn.Conv2d(in_channels * t, out_channels, 1, bias = False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "        residual_list = []\n",
        "        if t > 1:\n",
        "            residual_list += [expand]\n",
        "        residual_list += [depthwise, pointwise]\n",
        "        self.residual = nn.Sequential(*residual_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
        "            out = self.residual(x) + x\n",
        "        else:\n",
        "            out = self.residual(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, n_classes = 1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.first_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride = 2, padding = 1, bias = False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(inplace = True)\n",
        "        )\n",
        "\n",
        "        self.bottlenecks = nn.Sequential(\n",
        "            self.make_stage(32, 16, t = 1, n = 1),\n",
        "            self.make_stage(16, 24, t = 6, n = 2, stride = 2),\n",
        "            self.make_stage(24, 32, t = 6, n = 3, stride = 2),\n",
        "            self.make_stage(32, 64, t = 6, n = 4, stride = 2),\n",
        "            self.make_stage(64, 96, t = 6, n = 3),\n",
        "            self.make_stage(96, 160, t = 6, n = 3, stride = 2),\n",
        "            self.make_stage(160, 320, t = 6, n = 1)\n",
        "        )\n",
        "\n",
        "        self.last_conv = nn.Sequential(\n",
        "            nn.Conv2d(320, 1280, 1, bias = False),\n",
        "            nn.BatchNorm2d(1280),\n",
        "            nn.ReLU6(inplace = True)\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Sequential(\n",
        "        \tnn.Dropout(0.2),\n",
        "            nn.Linear(1280, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_conv(x)\n",
        "        x = self.bottlenecks(x)\n",
        "        x = self.last_conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1) # (N, C, 1, 1) -> (N, C)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def make_stage(self, in_channels, out_channels, t, n, stride = 1):\n",
        "        layers = [InvertedBottleneck(in_channels, out_channels, t, stride)]\n",
        "        in_channels = out_channels\n",
        "        for _ in range(n-1):\n",
        "            layers.append(InvertedBottleneck(in_channels, out_channels, t))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "model = MobileNetV2()"
      ],
      "metadata": {
        "id": "6gmhhTeyfJcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_accuracy(image, target, model):\n",
        "    batch_size = image.shape[0]\n",
        "    prediction = model(image)\n",
        "    _, pred_label = torch.max(prediction, dim=1)\n",
        "    is_correct = (pred_label == target)\n",
        "    return is_correct.cpu().numpy().sum() / batch_size"
      ],
      "metadata": {
        "id": "2nIJFCjCfTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "loss_func = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= 1E-3, momentum=0.9)"
      ],
      "metadata": {
        "id": "Y5b9nW8ofV6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(dataloaders, model, optimizer, loss_func, device):\n",
        "    losses = {}\n",
        "    accuracies = {}\n",
        "    for phase in [\"train\", \"val\"]:\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        for index, batch in enumerate(dataloaders[phase]):\n",
        "            image = batch[\"image\"].to(device)\n",
        "            target = batch[\"target\"].to(device).view(-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == \"train\"):\n",
        "                prediction = model(image)\n",
        "                loss = loss_func(prediction, target)\n",
        "\n",
        "                if phase == \"train\":\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_correct += get_accuracy(image, target, model)\n",
        "\n",
        "            if phase == \"train\" and index % 10 == 0:\n",
        "                print(f\"{index}/{len(dataloaders[phase])} - Running Loss: {loss.item()}\")\n",
        "\n",
        "        losses[phase] = running_loss / len(dataloaders[phase])\n",
        "        accuracies[phase] = running_correct / len(dataloaders[phase])\n",
        "    return losses, accuracies"
      ],
      "metadata": {
        "id": "03uEuG-KfXfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "model = MobileNetV2().to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    losses, accuracies = train_one_epoch(dataloaders, model, optimizer, loss_func, device)\n",
        "    print(f\"{epoch+1}/{num_epochs}-Train Loss: {losses['train']}, Val Loss: {losses['val']}\")\n",
        "    print(f\"{epoch+1}/{num_epochs}-Train Acc: {accuracies['train']}, Val Acc: {accuracies['val']}\")\n",
        "\n",
        "    if accuracies[\"val\"] > best_acc:\n",
        "        best_acc = accuracies[\"val\"]\n",
        "        best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "save_best_model(best_model, \"best_model.pth\")\n",
        "print(\"Best model saved successfully.\")\n"
      ],
      "metadata": {
        "id": "fJlp5gM2jo82"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}